{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praca domowa nr 6\n",
    "## Justyna Jankowiak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os.path as op\n",
    "import time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sklearn.cluster as cl\n",
    "from sklearn.neighbors import kneighbors_graph\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Funkcje\n",
    "Jeszcze być może trzy algorytmy, gdzie nie możemy zdefiniować ilości klastrów"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def FM(labels, labels_predicted):\n",
    "    df = pd.DataFrame(data = {\"labels\": labels, \"labels_predicted\": labels_predicted})\n",
    "    table = df.groupby([\"labels\", \"labels_predicted\"]).size()\n",
    "    table1 = df.groupby(\"labels\").size()\n",
    "    table2 = df.groupby(\"labels_predicted\").size()\n",
    "    n = len(labels)\n",
    "    T = (table**2).sum() - n\n",
    "    P = (table1**2).sum() - n\n",
    "    Q = (table2**2).sum() - n\n",
    "    B = T/np.sqrt(P*Q)\n",
    "    return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def predict_labels(X, y):\n",
    "    n_labels = len(np.unique(y))\n",
    "    \n",
    "    X = StandardScaler().fit_transform(X)\n",
    "    \n",
    "    ### kmeans\n",
    "    # kmeans++\n",
    "    kmeans_k = cl.KMeans(init = 'k-means++', n_clusters = n_labels)\n",
    "    \n",
    "    # random\n",
    "    kmeans_r = cl.KMeans(init = 'random', n_clusters = n_labels)\n",
    "\n",
    "    ### birch\n",
    "    birch = cl.Birch(n_clusters = n_labels)\n",
    "    \n",
    "    ### minibatch\n",
    "    minibatch = cl.MiniBatchKMeans(n_clusters = n_labels)\n",
    "    \n",
    "    ### spectral\n",
    "    # kmeans\n",
    "    spectral_k = cl.SpectralClustering(n_clusters = n_labels, eigen_solver = 'arpack',\n",
    "                                     affinity = \"nearest_neighbors\", assign_labels = 'kmeans')\n",
    "    \n",
    "    # discretize\n",
    "    spectral_d = cl.SpectralClustering(n_clusters = n_labels, eigen_solver = 'arpack',\n",
    "                                     affinity = \"nearest_neighbors\", assign_labels = 'discretize')\n",
    "    \n",
    "    ### agglomerative\n",
    "    # Ward linkage\n",
    "    connectivity = kneighbors_graph(X, n_neighbors = 10, include_self = False)\n",
    "    connectivity = 0.5 * (connectivity + connectivity.T)\n",
    "    agg_w = cl.AgglomerativeClustering(n_clusters = n_labels, linkage = 'ward', connectivity = connectivity)\n",
    "    \n",
    "    # complete linkage\n",
    "    agg_cl = cl.AgglomerativeClustering(\n",
    "        linkage = \"complete\", affinity = \"cityblock\", n_clusters = n_labels,\n",
    "        connectivity = connectivity)\n",
    "    \n",
    "    # avarage linkage\n",
    "    agg_al = cl.AgglomerativeClustering(\n",
    "        linkage = \"average\", affinity = \"cityblock\", n_clusters = n_labels,\n",
    "        connectivity = connectivity)\n",
    "               \n",
    "    # meanshift\n",
    "    #bandwidth = cl.estimate_bandwidth(X, quantile = 0.3)\n",
    "    #meanshift = cl.MeanShift(bandwidth = bandwidth, bin_seeding=True)\n",
    "    \n",
    "    # dbscan\n",
    "    #dbscan = cl.DBSCAN(eps = 0.2)\n",
    "    \n",
    "    # affinity\n",
    "    #affinity_propagation = cl.AffinityPropagation(damping = 0.9, preference = -200)\n",
    "    \n",
    "    names = [\"KMeans, init = 'kmeans++'\", \"KMeans, init = 'random'\", \"Birch\", \"MiniBatchKMeans\", \n",
    "            \"SpectralClustering, assign_labels = 'kmeans'\", \"SpectralClustering, assign_labels = 'discretize'\",\n",
    "            \"AgglomerativeClustering, linkage = 'ward'\", \"AgglomerativeClustering, linkage = 'complete'\",\n",
    "            \"AgglomerativeClustering, linkage = 'avarage'\"]\n",
    "    algorithms = [kmeans_k, kmeans_r, birch, minibatch, spectral_k, spectral_d, agg_w, agg_cl, agg_al]\n",
    "    results = [None] * len(algorithms)\n",
    "    \n",
    "    for i, a in enumerate(algorithms):\n",
    "        print(\"    Counting \" + names[i])\n",
    "        t0 = time.time()\n",
    "        a.fit(X)\n",
    "        t1 = time.time()\n",
    "        run_time = t1 - t0\n",
    "        if hasattr(a, 'labels_'):\n",
    "            y_pred = a.labels_.astype(np.int)\n",
    "        else:\n",
    "            y_pred = a.predict(X)\n",
    "        fm = FM(y, y_pred)\n",
    "        results[i] = (run_time, fm, y_pred)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Zbiory danych\n",
    "Jeszcze 6 zbiorów (3 binarne, 3 tekstowe, gdzie trzeba użyć odległości Hamminga i Levensteina)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dir_to_data = \"data\"\n",
    "data_names = [\"digits2k_pixels\", \n",
    "              #\"digits70k_pixels\", \n",
    "             \"iris\", \"iris5\", \"s1\", \"s2\", \"s3\", \"s4\", \"a1\", \"a2\", \"a3\",\n",
    "             \"g2-2-100\", \"g2-16-100\", \"g2-64-100\", \"unbalance\", \"Aggregation\", \"Compound\", \"pathbased\", \n",
    "             \"spiral\", \"D31\", \"R15\", \"flame\", \"jain\"]\n",
    "algorithms_names = [\"kmeans_k\", \"kmeans_r\", \"birch\", \"minibatch\", \"spectral_k\", \"spectral_d\", \n",
    "                    \"agg_w\", \"agg_cl\", \"agg_al\"]\n",
    "\n",
    "def load_data(data_name, dir_to_data):\n",
    "    data = np.loadtxt(op.join(dir_to_data, data_name + \".data.gz\"), ndmin = 2)\n",
    "    labels = np.loadtxt(op.join(dir_to_data, data_name + \".labels.gz\"), dtype = 'int')\n",
    "    return (data, labels)\n",
    "\n",
    "def summary_all(dir_to_data, data_names):\n",
    "    results_all = [None] * len(data_names)\n",
    "    for i, name in enumerate(data_names):\n",
    "        print(\"Data set \" + name)\n",
    "        data, labels = load_data(name, dir_to_data)\n",
    "        if name in [\"digits2k_pixels\", \"digits70k_pixels\"]:\n",
    "            data = data / 255.0\n",
    "        result = predict_labels(data, labels)\n",
    "        results_all[i] = result\n",
    "    return results_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_all = summary_all(dir_to_data, data_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def save_results(results_all, data_names, algorithms_names):\n",
    "    n_datasets = len(data_names)\n",
    "    n_algorithms = len(algorithms_names)\n",
    "    results_time = np.zeros((n_datasets, n_algorithms))\n",
    "    results_fm = results_time.copy()\n",
    "    print(\"Saving data to csv files.\")\n",
    "    for i in range(n_datasets):\n",
    "        results_labels = [None] * n_algorithms\n",
    "        for j in range(n_algorithms):\n",
    "            time = results_all[i][j][0]\n",
    "            results_time[i][j] = time\n",
    "            fm = results_all[i][j][1]\n",
    "            results_fm[i][j] = fm\n",
    "            labels = results_all[i][j][2]\n",
    "            results_labels[j] = labels\n",
    "        results_labels_pd = pd.DataFrame(data = results_labels, index = algorithms_names)\n",
    "        results_labels_pd = results_labels_pd.transpose()\n",
    "        results_labels_pd.to_csv(\"labels_\" + data_names[i] + \".csv\", header = True, index = False)\n",
    "    results_time_pd = pd.DataFrame(data = results_time, index = data_names, columns = algorithms_names)\n",
    "    results_time_pd.to_csv(\"benchmark_time.csv\")\n",
    "    results_fm_pd = pd.DataFrame(data = results_fm, index = data_names, columns = algorithms_names)\n",
    "    results_fm_pd.to_csv(\"benchmark_fm.csv\")\n",
    "    print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "save_results(results_all, data_names, algorithms_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Przekleić to jak bedzie juz ostateczne od pliku .py, a w notatniku zrobić jakieś wykresy, porównanie, dla danych dwowymiarowych narysowac (poszukac kodów w necie)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-c1d1ca490279>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mhamming\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mhamming\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mLevenshtein\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mLevenshtein\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'X' is not defined"
     ]
    }
   ],
   "source": [
    "from scipy.spatial.distance import hamming\n",
    "hamming(X[i], X[j])\n",
    "import Levenshtein\n",
    "Levenshtein.distance(X[i], X[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data/actg1.data.gz', dtype = 'str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import Levenshtein\n",
    "N = len(data)\n",
    "data_input = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        data_input[i][j] = Levenshtein.distance(data[i], data[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  0.,  55.,  63., ...,  54.,  53.,  48.],\n",
       "       [ 55.,   0.,  58., ...,  49.,  44.,  54.],\n",
       "       [ 63.,  58.,   0., ...,  60.,  54.,  60.],\n",
       "       ..., \n",
       "       [ 54.,  49.,  60., ...,   0.,  56.,  52.],\n",
       "       [ 53.,  44.,  54., ...,  56.,   0.,  54.],\n",
       "       [ 48.,  54.,  60., ...,  52.,  54.,   0.]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = np.genfromtxt('data/binstr1.data.gz', dtype = 'str')\n",
    "from scipy.spatial.distance import hamming\n",
    "N = len(data)\n",
    "data_input = np.zeros((N, N))\n",
    "for i in range(N):\n",
    "    for j in range(N):\n",
    "        data_input[i][j] = hamming(list(data[i]), list(data[j]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  1.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  0.,  1., ...,  1.,  1.,  1.],\n",
       "       [ 1.,  1.,  0., ...,  1.,  1.,  1.],\n",
       "       ..., \n",
       "       [ 1.,  1.,  1., ...,  0.,  1.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  0.,  1.],\n",
       "       [ 1.,  1.,  1., ...,  1.,  1.,  0.]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2499.0"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(data_input[5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "a = data[0] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1101110001101011111011101011010000110111100011010100010001001010100110000110110111001111011111110100'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '1',\n",
       " '0',\n",
       " '1',\n",
       " '0',\n",
       " '0']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
